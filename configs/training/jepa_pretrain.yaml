# JEPA pretraining configuration (placeholder values)
seed: 123
dataset_manifest: data/manifests/pretrain_a.jsonl

model:
  type: "conv"
  embedding_dim: 256
  projection_dim: 128

optimizer:
  name: "adam"
  lr: 1.0e-4
  weight_decay: 1.0e-6

training:
  batch_size: 512
  epochs: 10
  checkpoint_dir: artifacts/jepa/pretrain

augmentations:
  mask_ratio: 0.2
  color_shuffle: true
  random_crop: true

loss:
  objective: "cosine"
  temperature: 0.1
